{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ad6c8b6-05e1-4a53-996a-b1175b8fd139",
   "metadata": {},
   "source": [
    "# US PTO Patent RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95b1465-a282-4eb5-9184-18dea32cea53",
   "metadata": {},
   "source": [
    "This notebook demonstrates a simple RAG pipeline, used to summarize US patents from a specific date from a search phrase.\n",
    "\n",
    "The stages of the RAG pipeline are:\n",
    "\n",
    "1. Download and extract the patent data from the US PTO\n",
    "2. Convert the patents to embeddings, and index these embeddings\n",
    "3. Query the embeddings index, rerank the results and then summarize the top results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf8b046-9d78-403d-ada3-ffb9ce63b6bf",
   "metadata": {},
   "source": [
    "## Installing Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da13786a-09d1-4149-98e1-8333c167ef0f",
   "metadata": {},
   "source": [
    "The notebook uses:\n",
    "\n",
    "1. A self-authored library 'pipedata' to process the patent data\n",
    "2. A self-authored library 'xml-to-pydantic', to extract the patent data from the patent XML using XPath\n",
    "3. The cohere API to do embeddings, reranking and summarization\n",
    "4. The annoy library to do nearest-neighbor search in embeddings space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331ed932-a19d-4f59-b9ad-65a3ba64d2cc",
   "metadata": {},
   "source": [
    "In practice, we'd pin the library versions using eg poetry, but pip install will work in a pinch.\n",
    "\n",
    "Note: !pip install installs into the global Jupyter workspace, %pip install installs into the active kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "049f5f82-f4ce-4987-a145-d1689f12751c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pipedata[ops] xml-to-pydantic fsspec pyarrow ijson requests aiohttp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5fa3ecf-45eb-4446-a958-7c71bff6253a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cd9876a-8e28-4875-8895-47678f6ca340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install annoy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce71c23-6a61-4598-96a9-4ff27e9db744",
   "metadata": {},
   "source": [
    "## Global Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37425af9-0274-4b1e-9ba5-2cc52e326cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\".secrets\", \"r\") as f:\n",
    "    secrets = json.load(f)\n",
    "COHERE_API_KEY = secrets[\"cohere_api_key\"]\n",
    "del secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e874c0b5-ed10-490e-ad16-25cda8615692",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s: %(message)s\"\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c31f28-5811-4029-9496-298b1fdb24d9",
   "metadata": {},
   "source": [
    "## Downloading and processing the patents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0bb236-be61-4928-8343-612d69854862",
   "metadata": {},
   "source": [
    "The first step is to get the patents from the US PTO bulk data service, and to extract the patent data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b2cec59-d61c-4543-91b4-f673a222b2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from io import BytesIO\n",
    "from typing import Iterator\n",
    "\n",
    "from lxml import etree\n",
    "from pipedata.core import Stream, ops\n",
    "from pipedata.ops import zipped_files\n",
    "from pydantic import computed_field\n",
    "from xml_to_pydantic import XmlBaseModel, XmlField"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "405b3603-d3b9-43dc-bd60-5a0b5c651a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_xmls(files):\n",
    "    \"\"\"\n",
    "    The US patent office file is not a single XML\n",
    "    file, but many XMLs concatenated together. This just\n",
    "    splits on the starting line of each XML and yields\n",
    "    each true XML in turn.\n",
    "    \"\"\"\n",
    "    for file in files:\n",
    "        xml = []\n",
    "        for line in file.contents:\n",
    "            if line.startswith(b\"<?xml\"):\n",
    "                if len(xml) > 0:\n",
    "                    yield b\"\".join(xml)\n",
    "                xml = []\n",
    "            xml.append(line)\n",
    "        yield b\"\".join(xml)\n",
    "\n",
    "\n",
    "\n",
    "@ops.filtering\n",
    "def remove_genetic_sequences(xml) -> bool:\n",
    "    \"\"\"\n",
    "    The patent file has both patents and genetic sequences. Here, we\n",
    "    filter out the genetic sequences, which have a different structure.\n",
    "    \"\"\"\n",
    "    tree = etree.parse(BytesIO(xml))\n",
    "    if \"sequence-cwu\" in tree.docinfo.doctype:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "class Patent(XmlBaseModel):\n",
    "    patent_id: str = XmlField(xpath=\"normalize-space(string(/us-patent-grant/us-bibliographic-data-grant/publication-reference/document-id))\")\n",
    "    patent_type: str = XmlField(xpath=\"/us-patent-grant/us-bibliographic-data-grant/application-reference/@appl-type\")\n",
    "    title: str = XmlField(xpath=\"string(/us-patent-grant/us-bibliographic-data-grant/invention-title)\")\n",
    "    assignees: list[str] | None = XmlField(xpath=\"/us-patent-grant/us-bibliographic-data-grant/assignees/assignee/addressbook/orgname/text()\", default=None)\n",
    "    claims: str = XmlField(xpath=\"string(/us-patent-grant/claims)\")\n",
    "\n",
    "    @computed_field\n",
    "    def all_text(self) -> str:\n",
    "        return self.title + \"\\n\\n\" + self.claims\n",
    "\n",
    "\n",
    "@ops.mapping\n",
    "def extract_patent(xml):\n",
    "    \"\"\"\n",
    "    The patent file has a lot of information in it, eg bibliographic data\n",
    "    and citations. Here, we just extract the key data.\n",
    "    \"\"\"\n",
    "    return Patent.model_validate_xml(xml)\n",
    "\n",
    "\n",
    "def take_n(n):\n",
    "    \"\"\"\n",
    "    This is a helper function to run the stream for just n\n",
    "    elements, if needed for debugging.\n",
    "    \"\"\"\n",
    "    def taken(els):\n",
    "        for i, el in enumerate(els):\n",
    "            if i == n:\n",
    "                break\n",
    "            yield el\n",
    "\n",
    "    return taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bf9566d-61b3-4274-a49e-350187c41a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-07 15:44:07,754 - INFO: Initializing zipped files reader\n",
      "2024-06-07 15:44:07,755 - INFO: Opening zip file at https://bulkdata.uspto.gov/data/patent/grant/redbook/fulltext/2024/ipg240206.zip\n",
      "2024-06-07 15:44:08,578 - INFO: Found 1 files in zip file\n",
      "2024-06-07 15:44:08,579 - INFO: Reading file 0 (ipg240206.xml) from zip file\n",
      "2024-06-07 15:45:00,837 - INFO: Extracted 6812 patents\n"
     ]
    }
   ],
   "source": [
    "patent_grant_release_date = datetime.date(2024, 2, 6)\n",
    "\n",
    "url_template = \"https://bulkdata.uspto.gov/data/patent/grant/redbook/fulltext/{YYYY}/ipg{YYMMDD}.zip\"\n",
    "url = url_template.format(YYYY=patent_grant_release_date.strftime(\"%Y\"), YYMMDD=patent_grant_release_date.strftime(\"%y%m%d\"))\n",
    "\n",
    "patents = (\n",
    "    Stream([url])\n",
    "    .then(zipped_files)\n",
    "    .then(split_into_xmls)\n",
    "    .then(remove_genetic_sequences)\n",
    "    .then(extract_patent)\n",
    "    # .then(take_n(100))  # For debugging\n",
    ").to_list()\n",
    "\n",
    "logger.info(f\"Extracted {len(patents)} patents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25d58725-bd04-46e6-b918-d0a7d223c31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patent_id='US D1013321 S1 20240206' patent_type='design' title='Canine biscuit' assignees=None claims='\\n\\nThe ornamental design for a canine biscuit, as shown and described.\\n\\n' all_text='Canine biscuit\\n\\n\\n\\nThe ornamental design for a canine biscuit, as shown and described.\\n\\n'\n"
     ]
    }
   ],
   "source": [
    "print(patents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9977a5da-d0d0-4533-a117-90dce7d50011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'utility': 6107, 'design': 680, 'plant': 18, 'reissue': 7})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(patent.patent_type for patent in patents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56dd0b0-572e-44bf-8d2f-5b4aae6736d9",
   "metadata": {},
   "source": [
    "We now have a list of Patent objects in 'patents'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e6cf9a-78e0-4490-b594-0d9e8ed8eac2",
   "metadata": {},
   "source": [
    "## Converting patents to embeddings and indexing the embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e434befa-0893-4dbb-88df-22e68e21c9bc",
   "metadata": {},
   "source": [
    "This just sends the whole patent to the embeddings endpoint - even though the patent claim text can be quite long. An improvement could be made by separating the patent claims into chunks and finding embeddings for each chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f0497c7-5e06-4b2a-bbb5-2111edfccce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-07 15:45:01,503 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:01,532 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:01,540 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:01,577 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:01,606 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:01,644 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:01,746 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:05,385 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:05,692 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:05,763 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:05,971 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:05,974 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:06,130 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:06,202 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:06,315 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:06,486 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:06,648 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:06,698 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:07,028 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:07,066 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:07,190 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:07,259 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:07,474 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:07,552 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:07,676 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:07,799 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:07,934 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:08,042 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:08,111 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:08,333 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:08,408 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:08,490 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:08,771 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:08,828 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:09,012 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:09,030 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:09,231 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:09,244 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:09,752 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:09,753 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:10,171 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:10,296 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:10,554 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:10,564 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:10,692 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:10,819 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:10,989 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:11,040 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:11,222 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:11,374 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:11,498 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:11,620 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:11,774 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:11,971 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:12,026 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:12,155 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:12,328 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:12,480 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:12,516 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:12,845 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:12,951 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:13,198 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:13,212 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:13,526 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:13,646 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:13,688 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:13,846 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:14,084 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:14,394 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:14,722 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:14,915 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:21,876 - INFO: HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "import cohere\n",
    "from annoy import AnnoyIndex\n",
    "\n",
    "EMBED_MODEL = \"embed-english-v3.0\"\n",
    "DB_N_TREES = 10\n",
    "\n",
    "\n",
    "def get_embeddings_index(co, docs):\n",
    "    embeds = co.embed(\n",
    "        texts=docs,\n",
    "        model=EMBED_MODEL,\n",
    "        input_type=\"search_document\"\n",
    "    ).embeddings\n",
    "    \n",
    "    search_index = AnnoyIndex(len(embeds[0]), \"angular\")\n",
    "    for i, embed in enumerate(embeds):\n",
    "        search_index.add_item(i, embed)\n",
    "    search_index.build(DB_N_TREES)\n",
    "    return search_index\n",
    "    \n",
    "\n",
    "co = cohere.Client(COHERE_API_KEY)\n",
    "search_index = get_embeddings_index(co, [el.all_text for el in patents])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de07a62b-e841-44d2-a2a3-55db87c10b3a",
   "metadata": {},
   "source": [
    "At this stage, as well as the raw patent data in 'patents', we have a searchable embeddings index in 'search_index'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475f87d8-e291-4112-8439-5bed78ba7a89",
   "metadata": {},
   "source": [
    "## Querying and summarizing the patents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "027300cc-7078-456b-863f-e5dec72edc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(co, query, search_index, n_results):\n",
    "    query_embed = co.embed(\n",
    "        texts=[query],\n",
    "        model=EMBED_MODEL,\n",
    "        input_type=\"search_query\",\n",
    "    ).embeddings\n",
    "    \n",
    "    return search_index.get_nns_by_vector(\n",
    "        query_embed[0], n_results, include_distances=False\n",
    "    )\n",
    "\n",
    "\n",
    "def rerank(co, query, docs, n_results):\n",
    "    reranked_results = co.rerank(\n",
    "        model=\"rerank-english-v3.0\",\n",
    "        query=query,\n",
    "        documents=docs,\n",
    "        top_n=n_results,\n",
    "        return_documents=False,\n",
    "    )\n",
    "    return [docs[result.index] for result in reranked_results.results]\n",
    "\n",
    "\n",
    "def summarize(co, docs):\n",
    "    res = co.chat(\n",
    "      model=\"command-r-plus\",\n",
    "      message=\"Please summarize the dominant themes in the documents in under 500 words.\",\n",
    "      documents=docs\n",
    "    )\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52e6b445-d22e-419e-9b3b-56dcaca99239",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-07 15:45:24,229 - INFO: HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "2024-06-07 15:45:57,642 - INFO: HTTP Request: POST https://api.cohere.com/v1/chat \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "query = \"artificial intelligence\"\n",
    "initial_n = 100\n",
    "final_n = 10\n",
    "\n",
    "initial_ixs = search(co, query, search_index, initial_n)\n",
    "docs_to_rerank = [patents[i].all_text for i in initial_ixs]\n",
    "reranked_docs = rerank(co, query, docs_to_rerank, final_n)\n",
    "\n",
    "result = summarize(co, [{\"doc\": doc} for doc in reranked_docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35accf20-46b4-42b6-91de-635ce6ff7c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dominant themes in the documents revolve around the use of artificial intelligence (AI) and machine learning (ML) in various applications, including:\n",
      "\n",
      "- Cooking devices: AI is used to provide guidance and optimize the cooking process based on various sensors and user input.\n",
      "- 3D modeling: AI is employed to create 3D models of rooms by analyzing images from different perspectives and identifying objects, walls, and corners.\n",
      "- Train defect detection: AI, in combination with cameras and illumination, detects anomalies in moving trains.\n",
      "- Model reconstruction: AI models are reconstructed based on usage patterns and context information to improve performance and reliability.\n",
      "- Power optimization: Techniques are described to optimize power consumption in AI processors by dynamically turning resources on and off.\n",
      "- Chatbots: AI chatbots interact with human users to reduce the time spent by human agents, utilizing machine learning algorithms.\n",
      "- Photography: AI is used to categorize and organize photos, with capabilities to detect specific objects and perform related actions.\n",
      "- Encryption: AI devices are detailed that perform homomorphic encryption calculations and store encrypted data.\n",
      "- Active learning: AI systems employ iterative two-phase learning iterations to train classification models efficiently, utilizing bucketing techniques and annotation.\n",
      "- Robotic process automation: AI is utilized to select and chain ML models for robotic process automation, analyzing performance and deploying superior models.\n"
     ]
    }
   ],
   "source": [
    "print(result.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fb74b4-f199-4087-9bbe-a774adb9ddde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kernel-3.12",
   "language": "python",
   "name": "kernel-3.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
